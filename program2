import os
print(os.getcwd())
import os
print(os.getcwd())
from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_dir = r"C:\Users\DELL\resized-dataset\train"
val_dir   = r"C:\Users\DELL\resized-dataset\val"
test_dir  = r"C:\Users\DELL\resized-dataset\test"

datagen = ImageDataGenerator(rescale=1./255)

train_data = datagen.flow_from_directory(
    train_dir,
    target_size=(128, 128),
    batch_size=32,
    class_mode='categorical'
)

val_data = datagen.flow_from_directory(
    val_dir,
    target_size=(128, 128),
    batch_size=32,
    class_mode='categorical'
)

test_data = datagen.flow_from_directory(
    test_dir,
    target_size=(128, 128), batch_size=32,
    class_mode='categorical'
)
datset_path=r"C:\Users\DELL\resized-dataset"
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

# Build CNN model
model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(128,128,3)),
    MaxPooling2D(pool_size=(2,2)),

    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(pool_size=(2,2)),

    Conv2D(128, (3,3), activation='relu'),
    MaxPooling2D(pool_size=(2,2)),

    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(len(train_data.class_indices), activation='softmax')  # output layer
])

# Compile the model
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Now train
history = model.fit(
    train_data,
    validation_data=val_data,
    epochs=30
)
test_loss, test_acc = model.evaluate(test_data)
print(f"Test Accuracy: {test_acc*100:.2f}%")
from tensorflow.keras.callbacks import ReduceLROnPlateau

lr_reduction = ReduceLROnPlateau(monitor='val_loss', 
                                 patience=2, 
                                 factor=0.5, 
                                 min_lr=1e-6)
from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam

# -----------------------------
# Data Augmentation
# -----------------------------
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

val_datagen = ImageDataGenerator(rescale=1./255)

train_data = train_datagen.flow_from_directory(
    train_dir, target_size=(128,128), batch_size=32, class_mode='categorical'
)

val_data = val_datagen.flow_from_directory(
    val_dir, target_size=(128,128), batch_size=32, class_mode='categorical'
)

# -----------------------------
# Base Model (MobileNetV2)
# -----------------------------
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(128,128,3))

# Freeze base model layers (so we donâ€™t retrain ImageNet weights at first)
base_model.trainable = False

# -----------------------------
# Custom Classification Head
# -----------------------------
model = Sequential([
    base_model,
    GlobalAveragePooling2D(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(train_data.num_classes, activation='softmax')
])

# -----------------------------
# Compile Model
# -----------------------------
model.compile(optimizer=Adam(learning_rate=0.001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# -----------------------------
# Train Model
# -----------------------------
history = model.fit(
train_data,
    validation_data=val_data,
    epochs=10
)

# -----------------------------
# Evaluate
# -----------------------------
loss, acc = model.evaluate(val_data)
print(f"Validation Accuracy: {acc*100:.2f}%")
base_model.trainable = True
model.compile(optimizer=Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy'])
test_datagen = ImageDataGenerator(rescale=1./255)

test_data = test_datagen.flow_from_directory(
    test_dir, target_size=(128,128), batch_size=32, class_mode='categorical'
)

loss, acc = model.evaluate(test_data)
print(f"Test Accuracy: {acc*100:.2f}%")
# Test data generator (important: shuffle=False)
test_data = test_datagen.flow_from_directory(
    r"C:\Users\DELL\resized-dataset\test",
    target_size=(224,224),
    batch_size=32,
    class_mode="categorical",
    shuffle=False
)

# Get true labels
y_true = test_data.classes  

# Predict
y_pred_prob = model.predict(test_data, steps=len(test_data), verbose=1)
y_pred = np.argmax(y_pred_prob, axis=1)

# Report
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

target_names = list(test_data.class_indices.keys())
print(classification_report(y_true, y_pred, target_names=target_names))

cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(10,8))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", 
            xticklabels=target_names, 
            yticklabels=target_names)
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()
